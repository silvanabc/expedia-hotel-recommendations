{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Kaggle Challenge</h3>\n",
    "<h1>Expedia Hotel Recommendations</h1>\n",
    "<hr style=\"height:2px;border:none;color:#333;background-color:#333;\"/>\n",
    "<b>Part II - Data Processing</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "#Graphs libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Modeling and Pre-processing libraries\n",
    "import ml_metrics as metrics\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "##Global Parameters\n",
    "pd.set_option('display.max_columns', 500)\n",
    "sns.set(style=\"whitegrid\")\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 7.0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 11s, sys: 14.8 s, total: 4min 26s\n",
      "Wall time: 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ROWS = None\n",
    "# ROWS = 1000000\n",
    "\n",
    "expediaDF = pd.read_csv('data/train.csv.gz', \n",
    "                        nrows=ROWS,\n",
    "                        compression='gzip',\n",
    "                        error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (37670293, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>channel</th>\n",
       "      <th>srch_ci</th>\n",
       "      <th>srch_co</th>\n",
       "      <th>srch_adults_cnt</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>is_booking</th>\n",
       "      <th>cnt</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "      <th>hotel_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-08-11 07:46:59</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-08-27</td>\n",
       "      <td>2014-08-31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-08-11 08:22:12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-08-11 08:24:33</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>348</td>\n",
       "      <td>48862</td>\n",
       "      <td>2234.2641</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2014-08-29</td>\n",
       "      <td>2014-09-02</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-08-09 18:05:16</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>442</td>\n",
       "      <td>35390</td>\n",
       "      <td>913.1932</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-11-23</td>\n",
       "      <td>2014-11-28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1457</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-08-09 18:08:18</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>442</td>\n",
       "      <td>35390</td>\n",
       "      <td>913.6259</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2014-11-23</td>\n",
       "      <td>2014-11-28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>1457</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             date_time  site_name  posa_continent  user_location_country  \\\n",
       "0  2014-08-11 07:46:59          2               3                     66   \n",
       "1  2014-08-11 08:22:12          2               3                     66   \n",
       "2  2014-08-11 08:24:33          2               3                     66   \n",
       "3  2014-08-09 18:05:16          2               3                     66   \n",
       "4  2014-08-09 18:08:18          2               3                     66   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance  \\\n",
       "0                   348               48862                  2234.2641   \n",
       "1                   348               48862                  2234.2641   \n",
       "2                   348               48862                  2234.2641   \n",
       "3                   442               35390                   913.1932   \n",
       "4                   442               35390                   913.6259   \n",
       "\n",
       "   user_id  is_mobile  is_package  channel     srch_ci     srch_co  \\\n",
       "0       12          0           1        9  2014-08-27  2014-08-31   \n",
       "1       12          0           1        9  2014-08-29  2014-09-02   \n",
       "2       12          0           0        9  2014-08-29  2014-09-02   \n",
       "3       93          0           0        3  2014-11-23  2014-11-28   \n",
       "4       93          0           0        3  2014-11-23  2014-11-28   \n",
       "\n",
       "   srch_adults_cnt  srch_children_cnt  srch_rm_cnt  srch_destination_id  \\\n",
       "0                2                  0            1                 8250   \n",
       "1                2                  0            1                 8250   \n",
       "2                2                  0            1                 8250   \n",
       "3                2                  0            1                14984   \n",
       "4                2                  0            1                14984   \n",
       "\n",
       "   srch_destination_type_id  is_booking  cnt  hotel_continent  hotel_country  \\\n",
       "0                         1           0    3                2             50   \n",
       "1                         1           1    1                2             50   \n",
       "2                         1           0    1                2             50   \n",
       "3                         1           0    1                2             50   \n",
       "4                         1           0    1                2             50   \n",
       "\n",
       "   hotel_market  hotel_cluster  \n",
       "0           628              1  \n",
       "1           628              1  \n",
       "2           628              1  \n",
       "3          1457             80  \n",
       "4          1457             21  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape:\", expediaDF.shape)\n",
    "expediaDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-09 10:40:40.384450\n",
      "2019-05-09 10:40:53.250320\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "testingDF = pd.read_csv('data/test.csv.gz', \n",
    "#                         nrows=100000,\n",
    "                        compression='gzip',\n",
    "                        error_bad_lines=False)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2528243, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>site_name</th>\n",
       "      <th>posa_continent</th>\n",
       "      <th>user_location_country</th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>user_location_city</th>\n",
       "      <th>orig_destination_distance</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_mobile</th>\n",
       "      <th>is_package</th>\n",
       "      <th>channel</th>\n",
       "      <th>srch_ci</th>\n",
       "      <th>srch_co</th>\n",
       "      <th>srch_adults_cnt</th>\n",
       "      <th>srch_children_cnt</th>\n",
       "      <th>srch_rm_cnt</th>\n",
       "      <th>srch_destination_id</th>\n",
       "      <th>srch_destination_type_id</th>\n",
       "      <th>hotel_continent</th>\n",
       "      <th>hotel_country</th>\n",
       "      <th>hotel_market</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-03 17:09:54</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>174</td>\n",
       "      <td>37449</td>\n",
       "      <td>5539.0567</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-05-19</td>\n",
       "      <td>2016-05-23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12243</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>204</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-09-24 17:38:35</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>174</td>\n",
       "      <td>37449</td>\n",
       "      <td>5873.2923</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-05-12</td>\n",
       "      <td>2016-05-15</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14474</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>204</td>\n",
       "      <td>1540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-06-07 15:53:02</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>142</td>\n",
       "      <td>17440</td>\n",
       "      <td>3975.9776</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>2015-07-27</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11353</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2015-09-14 14:49:10</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>258</td>\n",
       "      <td>34156</td>\n",
       "      <td>1508.5975</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2015-09-14</td>\n",
       "      <td>2015-09-16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8250</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2015-07-17 09:32:04</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>467</td>\n",
       "      <td>36345</td>\n",
       "      <td>66.7913</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-07-22</td>\n",
       "      <td>2015-07-23</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11812</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id            date_time  site_name  posa_continent  user_location_country  \\\n",
       "0   0  2015-09-03 17:09:54          2               3                     66   \n",
       "1   1  2015-09-24 17:38:35          2               3                     66   \n",
       "2   2  2015-06-07 15:53:02          2               3                     66   \n",
       "3   3  2015-09-14 14:49:10          2               3                     66   \n",
       "4   4  2015-07-17 09:32:04          2               3                     66   \n",
       "\n",
       "   user_location_region  user_location_city  orig_destination_distance  \\\n",
       "0                   174               37449                  5539.0567   \n",
       "1                   174               37449                  5873.2923   \n",
       "2                   142               17440                  3975.9776   \n",
       "3                   258               34156                  1508.5975   \n",
       "4                   467               36345                    66.7913   \n",
       "\n",
       "   user_id  is_mobile  is_package  channel     srch_ci     srch_co  \\\n",
       "0        1          1           0        3  2016-05-19  2016-05-23   \n",
       "1        1          1           0       10  2016-05-12  2016-05-15   \n",
       "2       20          0           0        1  2015-07-26  2015-07-27   \n",
       "3       28          0           1       10  2015-09-14  2015-09-16   \n",
       "4       50          0           0        0  2015-07-22  2015-07-23   \n",
       "\n",
       "   srch_adults_cnt  srch_children_cnt  srch_rm_cnt  srch_destination_id  \\\n",
       "0                2                  0            1                12243   \n",
       "1                2                  0            1                14474   \n",
       "2                4                  0            1                11353   \n",
       "3                2                  0            1                 8250   \n",
       "4                2                  0            1                11812   \n",
       "\n",
       "   srch_destination_type_id  hotel_continent  hotel_country  hotel_market  \n",
       "0                         6                6            204            27  \n",
       "1                         7                6            204          1540  \n",
       "2                         1                2             50           699  \n",
       "3                         1                2             50           628  \n",
       "4                         1                2             50           538  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape:\", testingDF.shape)\n",
    "testingDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orig_destination_distance</td>\n",
       "      <td>13525001</td>\n",
       "      <td>0.359036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>srch_co</td>\n",
       "      <td>47084</td>\n",
       "      <td>0.001250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>srch_ci</td>\n",
       "      <td>47083</td>\n",
       "      <td>0.001250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature     count  percentage\n",
       "0  orig_destination_distance  13525001    0.359036\n",
       "1                    srch_co     47084    0.001250\n",
       "2                    srch_ci     47083    0.001250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingValues = expediaDF.isnull().sum().sort_values(ascending=False)\n",
    "missingValues = missingValues.to_frame().reset_index()\n",
    "missingValues.columns = [\"feature\", \"count\"]\n",
    "missingValues[\"percentage\"] = missingValues[\"count\"] / expediaDF.shape[0]\n",
    "print(\"Missing Values: \")\n",
    "missingValues[missingValues[\"count\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Removing checkin and checkout null rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows deleted:  47088 - % of the dataset:  0.13%\n",
      "CPU times: user 18.3 s, sys: 2.36 s, total: 20.6 s\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "countBefore = expediaDF.shape[0]\n",
    "# newExpediaDF = expediaDF.dropna(subset=['srch_co', 'srch_ci','orig_destination_distance'])\n",
    "newExpediaDF = expediaDF.dropna(subset=['srch_co', 'srch_ci'])\n",
    "countAfter = newExpediaDF.shape[0]\n",
    "deletedRows = countBefore - countAfter\n",
    "print(\"Rows deleted: \", deletedRows, \"- % of the dataset: \", \"{:.2%}\".format(deletedRows / countBefore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sbarboza/yes/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "newExpediaDF['orig_destination_distance'] = \\\n",
    "    newExpediaDF['orig_destination_distance'].fillna(newExpediaDF['orig_destination_distance'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37623205, 24)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newExpediaDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del expediaDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orig_destination_distance</td>\n",
       "      <td>847461</td>\n",
       "      <td>0.335198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>srch_ci</td>\n",
       "      <td>21</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>srch_co</td>\n",
       "      <td>17</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     feature   count  percentage\n",
       "0  orig_destination_distance  847461    0.335198\n",
       "1                    srch_ci      21    0.000008\n",
       "2                    srch_co      17    0.000007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingValues = testingDF.isnull().sum().sort_values(ascending=False)\n",
    "missingValues = missingValues.to_frame().reset_index()\n",
    "missingValues.columns = [\"feature\", \"count\"]\n",
    "missingValues[\"percentage\"] = missingValues[\"count\"] / testingDF.shape[0]\n",
    "print(\"Missing Values: \")\n",
    "missingValues[missingValues[\"count\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handling missing values for checkin and checkout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testingDF = testingDF.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform the datatype of checkin and checkout in date\n",
    "newExpediaDF['srch_ci'] = pd.to_datetime(newExpediaDF['srch_ci'], errors='coerce')\n",
    "newExpediaDF['srch_co'] = pd.to_datetime(newExpediaDF['srch_co'], errors='coerce')\n",
    "\n",
    "testingDF['srch_ci'] = pd.to_datetime(testingDF['srch_ci'], errors='coerce')\n",
    "testingDF['srch_co'] = pd.to_datetime(testingDF['srch_co'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handle missing values of checkin and checkout\n",
    "\n",
    "#fill with one day difference between checkin/out\n",
    "testingDF['srch_ci'] = testingDF['srch_ci'].fillna(testingDF['srch_co'] - datetime.timedelta(1))\n",
    "testingDF['srch_co'] = testingDF['srch_co'].fillna(testingDF['srch_ci'] + datetime.timedelta(1))\n",
    "\n",
    "#fill the left with the mode\n",
    "testingDF['srch_ci'] = testingDF['srch_ci'].fillna(testingDF['srch_ci'].mode()[0])\n",
    "testingDF['srch_co'] = testingDF['srch_co'].fillna(testingDF['srch_co'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Handling missing values for orig_destination_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = newExpediaDF.groupby(['user_location_region', 'srch_destination_id'])['orig_destination_distance']\\\n",
    "        .mean().to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location_region</th>\n",
       "      <th>srch_destination_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_location_region  srch_destination_id\n",
       "0                     0                   19\n",
       "1                     0                   21\n",
       "2                     0                   24\n",
       "3                     0                   27\n",
       "4                     0                   40"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingDF = testingDF[testingDF.orig_destination_distance.isnull()]\n",
    "df = missingDF.groupby(['user_location_region', 'srch_destination_id']).size().to_frame().reset_index()\n",
    "df = df.drop([0], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "newTestingDF = testingDF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "regions = df.user_location_region.unique()\n",
    "newTestingDF = testingDF.copy()\n",
    "count = 0\n",
    "res = []\n",
    "\n",
    "for region in regions:\n",
    "    destinations = df[df['user_location_region'] == region].srch_destination_id.unique()\n",
    "    \n",
    "    for dest in destinations:\n",
    "        origDestMean = mean[ \\\n",
    "        (mean.user_location_region == region) & \\\n",
    "        (mean.srch_destination_id == dest) \\\n",
    "        ]['orig_destination_distance']\n",
    "        \n",
    "        if(origDestMean.size > 0):\n",
    "            newTestingDF.loc[\n",
    "                (newTestingDF['orig_destination_distance'].isnull()) &\n",
    "                (newTestingDF['user_location_region'] == region) &\n",
    "                (newTestingDF['srch_destination_id'] == dest),\n",
    "                'orig_destination_distance'\n",
    "            ] = origDestMean.values[0]\n",
    "            res.append(origDestMean)\n",
    "        \n",
    "        count += 1\n",
    "        if(count % 100 == 0):\n",
    "            print(count)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where could not find any value for same user_location_region and  srch_destination_id on training set:\n",
    "# set the mean of orig_destination_distance in testing set.\n",
    "newTestingDF['orig_destination_distance'] = \\\n",
    "    newTestingDF['orig_destination_distance'].fillna(newTestingDF['orig_destination_distance'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingDF = newTestingDF\n",
    "del newTestingDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if all the missing values were eliminated\n",
    "assert testingDF.isnull().sum().sum() == 0\n",
    "assert newExpediaDF.isnull().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Include the is_booking column (all the testing data are booking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingDF['is_booking'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy here is to build a model on the last 6 months of 2014, from '2014-07-01' onwards in order to mirror the situation in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# newExpediaDF['date_time'] = newExpediaDF['date_time'].astype('datetime64[ns]')\n",
    "# newExpediaDF = newExpediaDF[newExpediaDF['date_time'] > datetime.date(2014,7,1)]\n",
    "# print(\"Shape: \",newExpediaDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newExpediaDF = newExpediaDF[newExpediaDF['is_booking'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Sampling the data for test models\n",
    "#Comment if you want to model the whole data\n",
    "N = 1000000\n",
    "trainingDF = trainingDF.sample(n=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = newExpediaDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows deleted:  221441 - % of the dataset:  0.59%\n",
      "CPU times: user 39.1 s, sys: 32.1 s, total: 1min 11s\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#removing outliers\n",
    "countBefore = newExpediaDF.shape[0]\n",
    "num_train = newExpediaDF.select_dtypes(include=[\"number\"])\n",
    "cat_train = newExpediaDF.select_dtypes(exclude=[\"number\"])\n",
    "idx = np.all(stats.zscore(num_train) < 7, axis=1)\n",
    "countAfter = np.sum(idx)\n",
    "deletedRows = countBefore - countAfter\n",
    "train_cleaned = pd.concat([num_train.loc[idx], cat_train.loc[idx]], axis=1)\n",
    "print(\"Rows deleted: \", deletedRows, \"- % of the dataset: \", \"{:.2%}\".format(deletedRows / countBefore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 680 ms, sys: 128 ms, total: 807 ms\n",
      "Wall time: 800 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "del num_train\n",
    "del cat_train\n",
    "del idx\n",
    "del newExpediaDF\n",
    "del countBefore\n",
    "del countAfter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 116 µs, sys: 15 µs, total: 131 µs\n",
      "Wall time: 26.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def encode_label(df):\n",
    "    X_cat = df.copy()\n",
    "    X_cat = df.select_dtypes(include=['object'])\n",
    "    X_enc = X_cat.copy()\n",
    "    X_enc = X_enc.apply(LabelEncoder().fit_transform)\n",
    "    mergedata = df.drop(X_cat.columns, axis=1)\n",
    "\n",
    "    return pd.concat([mergedata,X_enc], axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned[\"date_time\"] = train_cleaned[\"date_time\"].astype(str)\n",
    "train_cleaned[\"srch_ci\"] = train_cleaned[\"srch_ci\"].astype(str)\n",
    "train_cleaned[\"srch_co\"] = train_cleaned[\"srch_co\"].astype(str)\n",
    "\n",
    "testingDF[\"date_time\"] = testingDF[\"date_time\"].astype(str)\n",
    "testingDF[\"srch_ci\"] = testingDF[\"srch_ci\"].astype(str)\n",
    "testingDF[\"srch_co\"] = testingDF[\"srch_co\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 10s, sys: 1min 30s, total: 9min 41s\n",
      "Wall time: 8min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_cleaned = encode_label(train_cleaned)\n",
    "# testingDF = encode_label(testingDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37401764, 24)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingDF = train_cleaned\n",
    "del train_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34min 57s, sys: 35 s, total: 35min 32s\n",
      "Wall time: 35min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainingDF.to_csv(\"all_dataset_encoded_zscore3.csv\")\n",
    "# testingDF.to_csv(\"test_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the cleaned data\n",
    "Run this code if you have the cleaned data saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 324 ms, total: 17.1 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Uncomment if you want to read the train already cleaned\n",
    "# trainingDF = pd.read_csv('train_cleaned.csv')\n",
    "# trainingDF = trainingDF.drop(columns='Unnamed: 0')\n",
    "\n",
    "testingDF = pd.read_csv('test_cleaned_and_encoded.csv')\n",
    "testingDF = testingDF.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if the testing set has the correct number of rows\n",
    "assert testingDF.shape[0] == 2528243, \"Wrong number of testing set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set - Percentage of the whole dataset: 99%\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set - Percentage of the whole dataset: {:.0f}%\".format(trainingDF.shape[0]*100/37670293))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.55 s, sys: 4.01 s, total: 6.56 s\n",
      "Wall time: 5.97 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X = trainingDF.drop('hotel_cluster', axis=1)\n",
    "y = trainingDF[\"hotel_cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 s, sys: 4.91 s, total: 39.4 s\n",
      "Wall time: 39.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 89.36% of the expedia dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"Training with {:.2f}% of the expedia dataset\".format((X_train.shape[0] / 37670293)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.8 s, sys: 10.2 s, total: 33 s\n",
      "Wall time: 9.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_submission = scaler.transform(testingDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 µs, sys: 1 µs, total: 11 µs\n",
      "Wall time: 19.8 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "def predictAndEvaluate(model):\n",
    "    print(datetime.datetime.now())\n",
    "\n",
    "    m = model().fit(X_train, y_train)\n",
    "    print('Accuracy on training set: {:.2f}'.format(m.score(X_train, y_train)))\n",
    "    print('Accuracy on test set: {:.2f}'.format(m.score(X_test, y_test)))\n",
    "    print(datetime.datetime.now())\n",
    "    y_test_predicted_probability = m.predict_proba(X_test)\n",
    "\n",
    "    prob = y_test_predicted_probability.argsort()\n",
    "    predictions = []\n",
    "    for p in prob:\n",
    "        predictions.append(list(reversed(p[-5:])))\n",
    "        \n",
    "    targ = [[l] for l in y_test]\n",
    "    score = metrics.mapk(targ, predictions, k=5)\n",
    "    print('Accuracy of the predictions (MAP@5): {:.2f}'.format(score))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <b>Decision Tree</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-09 11:47:34.339069\n",
      "Accuracy on training set: 1.00\n",
      "Accuracy on test set: 0.33\n",
      "2019-05-09 12:56:40.915552\n",
      "Accuracy of the predictions (MAP@5): 0.34\n",
      "CPU times: user 1h 8min 52s, sys: 4min 37s, total: 1h 13min 29s\n",
      "Wall time: 1h 13min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = predictAndEvaluate(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-09 13:27:31.213174\n",
      "Accuracy on training set: 0.06\n",
      "Accuracy on test set: 0.06\n",
      "2019-05-09 13:32:46.279033\n",
      "Accuracy of the predictions (MAP@5): 0.11\n",
      "CPU times: user 9min 47s, sys: 1min 16s, total: 11min 4s\n",
      "Wall time: 7min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = predictAndEvaluate(LinearDiscriminantAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-09 13:35:13.334911\n",
      "2019-05-09 13:38:05.784122\n",
      "CPU times: user 3min 1s, sys: 4.38 s, total: 3min 6s\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(datetime.datetime.now())\n",
    "predicted_probability = best_model.predict_proba(X_submission)\n",
    "\n",
    "prob = predicted_probability.argsort()\n",
    "\n",
    "result = []\n",
    "for p in prob:\n",
    "    predictions = list(reversed(p[-5:]))\n",
    "    strPredictions = \" \".join(str(v) for v in predictions)\n",
    "    result.append(strPredictions)\n",
    "    \n",
    "resultDF = pd.DataFrame(result, columns=['hotel_cluster'])\n",
    "resultDF = pd.concat([testingDF.id, resultDF.hotel_cluster], axis=1)\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "resultDF.hotel_cluster.to_csv('predicted_with_pandas_lda_24.csv',header=True, index_label='id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
